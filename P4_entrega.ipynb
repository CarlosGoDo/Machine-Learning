{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2945329a",
   "metadata": {},
   "source": [
    "<h1>PRÁCTICA 4</h1>\n",
    "<h2>Imports y configuración del Notebook</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28cc584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\carlo\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import io\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Para que no salgan warnings de tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83a960d",
   "metadata": {},
   "source": [
    "<h2>Lectura de datos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f6eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo donde cada línea contiene \"ruta de la imagen\" y \"número de personas que aparecen en la imagen\"\n",
    "ruta_archivo = 'train.txt'\n",
    "\n",
    "rutas = []\n",
    "cantidades = []\n",
    "\n",
    "# Leer el archivo\n",
    "with open(ruta_archivo, 'r') as archivo:\n",
    "    lineas = archivo.readlines()\n",
    "    # Por cada línea\n",
    "    for linea in lineas:\n",
    "        # Separar la línea en partes usando espacios en blanco\n",
    "        partes = linea.split()  \n",
    "        # La primera parte es la ruta de la imagen\n",
    "        ruta = partes[0]\n",
    "        # La segunda parte es el número de personas que aparecen en la imagen\n",
    "        cantidad = int(partes[1])\n",
    "        # Actualizar listas\n",
    "        rutas.append(ruta)\n",
    "        cantidades.append(cantidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d246735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer todas las imágenes\n",
    "image_collection = io.ImageCollection('./train/train/train/*.png')\n",
    "\n",
    "# El conjunto de train será la colección de imágenes de las carpetas train\n",
    "# El conjunto de test serán las cantidades reales obtenidas del archivo anterior\n",
    "x_train = np.stack(image_collection)\n",
    "y_train = np.array(cantidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db878aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 158, 158)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar el tamaño del conjunto de train (15000 imágenes de 158x158)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21abec8",
   "metadata": {},
   "source": [
    "<h2>Normalización de los datos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13718240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de que las imágenes sean en escala de grises, se agregará una nueva dimensión para los canales RGB\n",
    "x_train = np.expand_dims(x_train, axis = -1)\n",
    "# Convertir las imágenes a float32\n",
    "x_train = x_train.astype(\"float32\")\n",
    "\n",
    "# Obtener el conjunto de train normalizado (Aplicar Z-Score Normalization, donde la media es 0 y la desviación\n",
    "# estándar es 1)\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train_normalized = (x_train.copy() - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7021e8",
   "metadata": {},
   "source": [
    "<h2>Creación del modelo de CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a131cf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\carlo\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\carlo\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\carlo\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "500/500 [==============================] - 318s 615ms/step - loss: 9.8879 - root_mean_squared_error: 3.1445 - lr: 3.0000e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 291s 583ms/step - loss: 2.7600 - root_mean_squared_error: 1.6613 - lr: 3.0000e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 294s 588ms/step - loss: 2.1403 - root_mean_squared_error: 1.4630 - lr: 3.0000e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 222s 443ms/step - loss: 2.0214 - root_mean_squared_error: 1.4218 - lr: 3.0000e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 213s 427ms/step - loss: 1.6555 - root_mean_squared_error: 1.2867 - lr: 3.0000e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 251s 501ms/step - loss: 1.4817 - root_mean_squared_error: 1.2173 - lr: 3.0000e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 295s 591ms/step - loss: 1.3291 - root_mean_squared_error: 1.1529 - lr: 3.0000e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 321s 642ms/step - loss: 1.2381 - root_mean_squared_error: 1.1127 - lr: 3.0000e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 316s 632ms/step - loss: 1.0340 - root_mean_squared_error: 1.0169 - lr: 3.0000e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 332s 665ms/step - loss: 0.8981 - root_mean_squared_error: 0.9477 - lr: 3.0000e-04\n",
      "500/500 [==============================] - 105s 100ms/step - loss: 1.1901 - root_mean_squared_error: 1.0909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1901334524154663, 1.0909323692321777]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Definición del modelo secuencial Keras\n",
    "# Definir una capa Input (entrada) de 158x158x1, por lo tanto, las imágenes de entrada serán de 158x158 en escala de grises\n",
    "# Definir capas Conv2D (convolución) con activación RELU para aprender patrones\n",
    "# Definir capas max-pooling para reducir el tamaño de las características extraídas\n",
    "# Añadir capa Flatten (Aplanar) para aplanar las características para prepararlas para la siguiente capa\n",
    "# Añadir capas Dense (Densa) para la salida del modelo. La última capa solo tiene una unidad ya que solo se espera\n",
    "# una única predicción numérica.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape = (158, 158, 1)),\n",
    "        layers.Conv2D(16, 3, padding = 'valid', activation = 'relu'),\n",
    "        layers.Conv2D(32, 3, activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "        layers.Conv2D(64, 3, activation = 'relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation = 'relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## Compilación del modelo\n",
    "# Compilar usando la función de pérdida mean_squared_error para medir la diferencia entre las predicciones y los valores reales\n",
    "# Utilizar un optimizador Adam con una tasa de aprendizaje de 1e-4\n",
    "# Agregar RootMeanSquaredError para evaluar el rendimiento durante el entrenamiento\n",
    "model.compile(\n",
    "    loss = 'mean_squared_error',\n",
    "    optimizer = keras.optimizers.Adam(learning_rate =3e-4),\n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "## Entrenamiento del modelo\n",
    "# Utilizar un callback ReduceLROnPlateau para reducir la tasa de aprendizaje cuando la pérdida deja de disminuir\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor = 'loss',\n",
    "    factor = 0.1,\n",
    "    patience = 1,\n",
    "    min_lr = 0.000003\n",
    ")\n",
    "\n",
    "# Entrenar el modelo usando el conjunto de entrenamiento, usar lotes de 30 muestras, entrenar durante 10 épicas y\n",
    "# usar el callback creado anteriormente\n",
    "model.fit(x_train_normalized, y_train, batch_size = 30, epochs = 10, callbacks = [lr_callback])\n",
    "\n",
    "## Evaluación del modelo\n",
    "# Evaular en modelo con los mismos datos de entrenamiento y un tamaño de lote de 30\n",
    "model.evaluate(x_train_normalized, y_train, batch_size = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ebda6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 156, 156, 16)      160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 154, 154, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 77, 77, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 37, 37, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 35, 35, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 156800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                10035264  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10132481 (38.65 MB)\n",
      "Trainable params: 10132481 (38.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el resumen del modelo\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a36808",
   "metadata": {},
   "source": [
    "<h2>Predicción del conjunto de test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3726c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 140ms/step\n"
     ]
    }
   ],
   "source": [
    "# Leer todas las imágenes del test\n",
    "image_collection_test = io.ImageCollection('./test/test/test/*.png')\n",
    "\n",
    "# El conjunto X de test será la colección de imágenes de las carpetas test\n",
    "# En caso de que las imágenes sean en escala de grises, se agregará una nueva dimensión para los canales RGB\n",
    "x_test = np.stack(image_collection_test)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Obtener el conjunto de test normalizado (Aplicar Z-Score Normalization, donde la media es 0 y la desviación\n",
    "# estándar es 1)\n",
    "x_test_normalized = (x_test.copy() - mean) / std\n",
    "\n",
    "# Predecir los resultados del test usando el modelo entrenado previamente\n",
    "y_pred = model.predict(x_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4077a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que y_pred es tu predicción\n",
    "df_output = pd.DataFrame(y_pred, columns=['prediction'])\n",
    "df_output.index.name = 'index'\n",
    "df_output.to_csv('output/session4/baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef15b1f",
   "metadata": {},
   "source": [
    "\n",
    "Práctica realizada por Adrián Galán Pacheco, Pablo Noriega Vázquez y Carlos Gómez Domínguez."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
